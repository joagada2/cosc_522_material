{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7a0bc4-e54a-41c8-99bf-d96da6ae37d8",
   "metadata": {},
   "source": [
    "## MODULE FOR TRAINING DIFFERENT CLASSIFICATION ALGORITHM AND OBTAINING RESULTS IN LINE WITH PROF REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c56a1-d9f0-4001-9195-a5a2d2b404c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to process in chunks to prevent memory issues\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Minimum Euclidean Distance Classifier with dual batch processing\n",
    "def minimum_euclidean_classifier(train_data, train_labels, test_data, batch_size=BATCH_SIZE):\n",
    "    n_test = test_data.shape[0]\n",
    "    n_train = train_data.shape[0]\n",
    "    predicted_labels = np.zeros(n_test)\n",
    "\n",
    "    for i in range(0, n_test, batch_size):  # Process test data in chunks\n",
    "        end_test_idx = min(i + batch_size, n_test)\n",
    "        test_batch = test_data[i:end_test_idx]\n",
    "        \n",
    "        min_distances = np.full(end_test_idx - i, np.inf)  # To store the minimum distances for each test example\n",
    "        best_labels = np.zeros(end_test_idx - i)           # To store the best labels for each test example\n",
    "\n",
    "        for j in range(0, n_train, batch_size):  # Process train data in chunks\n",
    "            end_train_idx = min(j + batch_size, n_train)\n",
    "            train_batch = train_data[j:end_train_idx]\n",
    "            \n",
    "            # Compute Euclidean distances between test batch and current train batch\n",
    "            distances = np.linalg.norm(test_batch[:, np.newaxis] - train_batch, axis=2)\n",
    "            \n",
    "            # Find the minimum distance and corresponding label\n",
    "            min_indices = np.argmin(distances, axis=1)\n",
    "            current_distances = np.min(distances, axis=1)\n",
    "            \n",
    "            # Update the best labels for each test sample\n",
    "            for idx, dist in enumerate(current_distances):\n",
    "                if dist < min_distances[idx]:\n",
    "                    min_distances[idx] = dist\n",
    "                    best_labels[idx] = train_labels[j + min_indices[idx]]\n",
    "\n",
    "        predicted_labels[i:end_test_idx] = best_labels\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# KNN Classifier with batch processing\n",
    "def knn_classifier(train_data, train_labels, test_data, k=15, batch_size=10):\n",
    "    n_test = test_data.shape[0]\n",
    "    predicted_labels = np.zeros(n_test)\n",
    "\n",
    "    for i in range(0, n_test, batch_size):\n",
    "        end_idx = min(i + batch_size, n_test)\n",
    "        test_batch = test_data[i:end_idx]\n",
    "        \n",
    "        # Calculate distances between test_batch and all training samples\n",
    "        distances = np.linalg.norm(test_batch[:, np.newaxis] - train_data, axis=2)\n",
    "        \n",
    "        # Get the indices of the k nearest neighbors\n",
    "        knn_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "        \n",
    "        # Get the labels of the k nearest neighbors\n",
    "        knn_labels = train_labels[knn_indices]\n",
    "        \n",
    "        # Predict the label as the most common label among the k nearest neighbors\n",
    "        for idx, neighbors in enumerate(knn_labels):\n",
    "            predicted_labels[i + idx] = np.bincount(neighbors.astype(int)).argmax()\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Neural Network Classifier with sigmoid activation function\n",
    "def neural_network(X_train, y_train, X_test, hidden_layer_size=15, num_epochs=500, learning_rate=3):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Convert y_train to integer type, if it's not already\n",
    "    y_train = y_train.astype(int)\n",
    "    \n",
    "    n_input = X_train.shape[1]\n",
    "    n_output = len(np.unique(y_train))\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    W1 = 0.01 * np.random.randn(n_input, hidden_layer_size)\n",
    "    b1 = np.zeros((1, hidden_layer_size))\n",
    "    W2 = 0.01 * np.random.randn(hidden_layer_size, n_output)\n",
    "    b2 = np.zeros((1, n_output))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass with sigmoid activation\n",
    "        hidden_layer = 1 / (1 + np.exp(-(np.dot(X_train, W1) + b1)))  # Sigmoid activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # Softmax\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "        # Compute loss (Cross-Entropy)\n",
    "        loss = -np.sum(np.log(probs[np.arange(len(y_train)), y_train])) / len(y_train)\n",
    "\n",
    "        # Backpropagation\n",
    "        dscores = probs\n",
    "        dscores[np.arange(len(y_train)), y_train] -= 1\n",
    "        dscores /= len(y_train)\n",
    "\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "        dhidden = np.dot(dscores, W2.T) * hidden_layer * (1 - hidden_layer)  # Gradient for sigmoid\n",
    "\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "    # Prediction for test data\n",
    "    hidden_layer = 1 / (1 + np.exp(-(np.dot(X_test, W1) + b1)))  # Sigmoid activation\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_labels = np.argmax(scores, axis=1)\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Function to evaluate performance of classifiers\n",
    "def evaluate_performance(X_train, y_train, X_test, y_test):\n",
    "    performance_table = {}\n",
    "\n",
    "    # Minimum Euclidean Distance Classifier\n",
    "    start_time = time.time()\n",
    "    predicted_labels = minimum_euclidean_classifier(X_train, y_train, X_test)\n",
    "    test_time = time.time() - start_time\n",
    "    accuracy = np.mean(predicted_labels == y_test)\n",
    "    performance_table[\"Min Euclidean\"] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Train Time\": test_time,\n",
    "        \"Test Time\": test_time\n",
    "    }\n",
    "\n",
    "    # KNN Classifier\n",
    "    start_time = time.time()\n",
    "    predicted_labels = knn_classifier(X_train, y_train, X_test, k=15, batch_size=10)\n",
    "    test_time = time.time() - start_time\n",
    "    accuracy = np.mean(predicted_labels == y_test)\n",
    "    performance_table[\"KNN\"] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Train Time\": test_time, \n",
    "        \"Test Time\": test_time\n",
    "    }\n",
    "\n",
    "    # Neural Network Classifier\n",
    "    start_time = time.time()\n",
    "    predicted_labels = neural_network(X_train, y_train, X_test)\n",
    "    test_time = time.time() - start_time\n",
    "    accuracy = np.mean(predicted_labels == y_test)\n",
    "    performance_table[\"Neural Network\"] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Train Time\": test_time,\n",
    "        \"Test Time\": 0\n",
    "    }\n",
    "\n",
    "    # Convert performance table to DataFrame for better readability\n",
    "    df_performance = pd.DataFrame.from_dict(performance_table, orient='index')\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58117e-f08e-4f54-91b1-5d6db6b86dd7",
   "metadata": {},
   "source": [
    "## FUNCTION FOR PREPARING DATA FOR THE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d7bca-f68b-4135-b627-7ffec78b96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preparing the dataset for training\n",
    "def split_data(df, target_column, train_size=0.7):\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Convert the DataFrame to a NumPy array\n",
    "    data = df.to_numpy()\n",
    "\n",
    "    # Get the index for splitting based on the train size ratio\n",
    "    split_index = int(len(data) * train_size)\n",
    "\n",
    "    # Split the data into features and labels\n",
    "    X = data[:, :-1]  # All columns except the last one (assuming target is the last column)\n",
    "    y = data[:, -1]   # The last column (target labels)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train = X[:split_index, :]\n",
    "    y_train = y[:split_index]\n",
    "\n",
    "    X_test = X[split_index:, :]\n",
    "    y_test = y[split_index:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e1acb-d1ad-4ede-b3e3-5adf4829fcb4",
   "metadata": {},
   "source": [
    "## PREPARE DATA USING THE ABOVE FUNCTION\n",
    "Input dataset here should be dataframe with label column as the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e9464-3f0b-42b6-a4a3-1f87c4e4fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into X_train, y_train, X_test, and y_test\n",
    "X_train, y_train, X_test, y_test = split_data(nX, target_column='label', train_size=0.7)\n",
    "\n",
    "# Display the result shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cb3da-b382-4901-80bb-7033d5dbe628",
   "metadata": {},
   "source": [
    "## TRAIN AND PRINT PERFORMANCE REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a80f5-41aa-4223-a693-81f2a84a5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_results = evaluate_performance(X_train, y_train, X_test, y_test)\n",
    "print(performance_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
