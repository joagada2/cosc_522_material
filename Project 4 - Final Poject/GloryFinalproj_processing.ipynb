{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oS61yfwyGyya",
    "outputId": "bec90fd8-6d8f-457c-8996-7e04957182f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Classifier  Accuracy  Runtime (s)\n",
      "0               KNN  0.843137     0.114703\n",
      "1  Minimum Distance  0.817647     0.001092\n",
      "2               SVM  0.850980     2.185329\n",
      "3               ANN  0.858824     2.876361\n",
      "4       Naive Bayes  0.800000     0.007266\n",
      "5           XGBoost  0.860784     0.915887\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('data_pca.csv')\n",
    "\n",
    "# Minimum Distance Classifier\n",
    "class MinimumDistanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        self.class_means_ = {label: X[y == label].mean(axis=0) for label in np.unique(y)}\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = np.array([\n",
    "            np.linalg.norm(X - mean, axis=1) for mean in self.class_means_.values()\n",
    "        ]).T\n",
    "        return self.classes_[np.argmin(distances, axis=1)]\n",
    "\n",
    "# Classifier Modules\n",
    "def knn_classifier(X_train, X_test, y_train, y_test, n_neighbors=5):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "def min_dist_classifier(X_train, X_test, y_train, y_test):\n",
    "    clf = MinimumDistanceClassifier()\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "def svm_classifier(X_train, X_test, y_train, y_test, kernel='linear'):\n",
    "    clf = SVC(kernel=kernel, probability=True)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "def ann_classifier(X_train, X_test, y_train, y_test, hidden_layer_sizes=(100,)):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=300, random_state=42)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "def naive_bayes_classifier(X_train, X_test, y_train, y_test):\n",
    "    clf = GaussianNB()\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "def xgboost_classifier(X_train, X_test, y_train, y_test):\n",
    "    clf = XGBClassifier(eval_metric='logloss')  # Removed use_label_encoder\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "# Evaluation Module\n",
    "def evaluate_classifiers(X, y, test_size=0.3, random_state=42):\n",
    "    results = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Standardize Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    classifiers = {\n",
    "        \"KNN\": knn_classifier,\n",
    "        \"Minimum Distance\": min_dist_classifier,\n",
    "        \"SVM\": svm_classifier,\n",
    "        \"ANN\": ann_classifier,\n",
    "        \"Naive Bayes\": naive_bayes_classifier,\n",
    "        \"XGBoost\": xgboost_classifier\n",
    "    }\n",
    "\n",
    "    for name, func in classifiers.items():\n",
    "        accuracy, runtime = func(X_train, X_test, y_train, y_test)\n",
    "        results.append({\"Classifier\": name, \"Accuracy\": accuracy, \"Runtime (s)\": runtime})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # Assuming `data` is a Pandas DataFrame\n",
    "    # Separate features (X) and labels (y)\n",
    "    X = data.iloc[:, :-1].values  # All columns except the last as features\n",
    "    y = data.iloc[:, -1].values   # The last column as labels\n",
    "\n",
    "    # Ensure labels are integers (required by some classifiers)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Evaluate Classifiers\n",
    "    results_df = evaluate_classifiers(X, y)\n",
    "\n",
    "    # Print Results\n",
    "    print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYOaqp45QT7m",
    "outputId": "d28e90c4-955e-4304-80a8-147d05e4d637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Classifier  Accuracy  Runtime (s)\n",
      "0               KNN  0.850980     0.044084\n",
      "1  Minimum Distance  0.694118     0.010402\n",
      "2               SVM  0.817647     1.763977\n",
      "3               ANN  0.841176     7.277627\n",
      "4       Naive Bayes  0.105882     0.007295\n",
      "5           XGBoost  0.892157     0.511757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Dataset\n",
    "    data = pd.read_csv('data-2.csv')\n",
    "\n",
    "    # Separate features (X) and labels (y)\n",
    "    X = data.iloc[:, :-1].values  # All columns except the last as features\n",
    "    y = data.iloc[:, -1].values   # The last column as labels\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')  # Replace NaN with column mean\n",
    "    X = imputer.fit_transform(X)\n",
    "\n",
    "    # Ensure labels are integers (required by some classifiers)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Evaluate Classifiers\n",
    "    results_df = evaluate_classifiers(X, y)\n",
    "\n",
    "    # Print Results\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbQ4vWZPUSu3",
    "outputId": "5a905cec-92dd-4eaf-c279-def72e7fbe3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Classifier  Accuracy  Runtime (s)\n",
      "0                             KNN  0.850980     0.260188\n",
      "1                             SVM  0.860784    18.354815\n",
      "2                             ANN  0.835294     7.258079\n",
      "3                         XGBoost  0.888235   159.974781\n",
      "4  Ensemble (XGBoost + KNN + SVM)  0.858824     2.002827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Fine-tuned KNN Classifier\n",
    "def knn_classifier(X_train, X_test, y_train, y_test):\n",
    "    params = {'n_neighbors': [5, 7, 9, 11], 'weights': ['uniform', 'distance']}\n",
    "    grid_search = GridSearchCV(KNeighborsClassifier(), params, cv=3)\n",
    "    start = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start, clf\n",
    "\n",
    "# Fine-tuned SVM Classifier\n",
    "def svm_classifier(X_train, X_test, y_train, y_test):\n",
    "    params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "    grid_search = GridSearchCV(SVC(probability=True), params, cv=3)\n",
    "    start = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start, clf\n",
    "\n",
    "# Fine-tuned ANN Classifier\n",
    "def ann_classifier(X_train, X_test, y_train, y_test):\n",
    "    params = {\n",
    "        'hidden_layer_sizes': [(100,), (150, 100)],\n",
    "        'learning_rate_init': [1, 0.01],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "    grid_search = GridSearchCV(MLPClassifier(random_state=42), params, cv=3)\n",
    "    start = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start, clf\n",
    "\n",
    "# Fine-tuned XGBoost Classifier\n",
    "def xgboost_classifier(X_train, X_test, y_train, y_test):\n",
    "    params = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    grid_search = GridSearchCV(XGBClassifier(eval_metric='mlogloss', verbosity=0), params, cv=3)\n",
    "    start = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start, clf\n",
    "\n",
    "# Ensemble Classifier: Voting Classifier with XGBoost and KNN\n",
    "def ensemble_classifier(X_train, X_test, y_train, y_test, models):\n",
    "    start = time.time()\n",
    "    voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    return accuracy_score(y_test, y_pred), end - start\n",
    "\n",
    "# Evaluation Module\n",
    "def evaluate_classifiers(X, y, test_size=0.3, random_state=42):\n",
    "    results = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Standardize Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    classifiers = {\n",
    "        \"KNN\": knn_classifier,\n",
    "        \"SVM\": svm_classifier,\n",
    "        \"ANN\": ann_classifier,\n",
    "        \"XGBoost\": xgboost_classifier\n",
    "    }\n",
    "\n",
    "    # Evaluate individual classifiers\n",
    "    trained_models = []\n",
    "    for name, func in classifiers.items():\n",
    "        accuracy, runtime, model = func(X_train, X_test, y_train, y_test)\n",
    "        results.append({\"Classifier\": name, \"Accuracy\": accuracy, \"Runtime (s)\": runtime})\n",
    "        trained_models.append((name, model))\n",
    "\n",
    "    # Ensemble Classifier\n",
    "    ensemble_accuracy, ensemble_runtime = ensemble_classifier(X_train, X_test, y_train, y_test, trained_models)\n",
    "    results.append({\"Classifier\": \"Ensemble (XGBoost + KNN + SVM)\", \"Accuracy\": ensemble_accuracy, \"Runtime (s)\": ensemble_runtime})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Dataset\n",
    "    data = pd.read_csv('data-2.csv')\n",
    "\n",
    "    # Separate features (X) and labels (y)\n",
    "    X = data.iloc[:, :-1].values  # All columns except the last as features\n",
    "    y = data.iloc[:, -1].values   # The last column as labels\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')  # Replace NaN with column mean\n",
    "    X = imputer.fit_transform(X)\n",
    "\n",
    "    # Ensure labels are integers (required by some classifiers)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Evaluate Classifiers\n",
    "    results_df = evaluate_classifiers(X, y)\n",
    "\n",
    "    # Print Results\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-cxtVHQjKB-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
